20/03/22 21:36:23 INFO SparkContext: Running Spark version 2.4.1
20/03/22 21:36:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/22 21:36:24 INFO SparkContext: Submitted application: wordcount
20/03/22 21:36:24 INFO SecurityManager: Changing view acls to: Rajesh
20/03/22 21:36:24 INFO SecurityManager: Changing modify acls to: Rajesh
20/03/22 21:36:24 INFO SecurityManager: Changing view acls groups to: 
20/03/22 21:36:24 INFO SecurityManager: Changing modify acls groups to: 
20/03/22 21:36:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Rajesh); groups with view permissions: Set(); users  with modify permissions: Set(Rajesh); groups with modify permissions: Set()
20/03/22 21:36:25 INFO Utils: Successfully started service 'sparkDriver' on port 62232.
20/03/22 21:36:25 INFO SparkEnv: Registering MapOutputTracker
20/03/22 21:36:25 INFO SparkEnv: Registering BlockManagerMaster
20/03/22 21:36:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/03/22 21:36:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/03/22 21:36:25 INFO DiskBlockManager: Created local directory at C:\Users\Rajesh\AppData\Local\Temp\blockmgr-52caa765-d02c-46bc-8515-0b771995df51
20/03/22 21:36:25 INFO MemoryStore: MemoryStore started with capacity 1992.9 MB
20/03/22 21:36:25 INFO SparkEnv: Registering OutputCommitCoordinator
20/03/22 21:36:25 INFO log: Logging initialized @8133ms
20/03/22 21:36:25 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/03/22 21:36:26 INFO Server: Started @8224ms
20/03/22 21:36:26 INFO AbstractConnector: Started ServerConnector@2e720162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/03/22 21:36:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@d5ae57e{/jobs,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4c168660{/jobs/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@52b56a3e{/jobs/job,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@36b0fcd5{/stages,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@716a7124{/stages/stage/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@77192705{/stages/pool,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@226642a5{/stages/pool/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7e809b79{/storage,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5cc126dc{/storage/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@625e134e{/storage/rdd,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@72bd06ca{/storage/rdd/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@89c10b7{/environment,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5dbe30be{/environment/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fe89c24{/executors,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@55795845{/executors/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3d08f3f5{/executors/threadDump,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@119f1f2a{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1a1da881{/static,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@53e211ee{/,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@41a90fa8{/api,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@18a3962d{/jobs/job/kill,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@78aea4b9{/stages/stage/kill,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-K1V13LI:4040
20/03/22 21:36:26 INFO Executor: Starting executor ID driver on host localhost
20/03/22 21:36:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62241.
20/03/22 21:36:26 INFO NettyBlockTransferService: Server created on DESKTOP-K1V13LI:62241
20/03/22 21:36:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/03/22 21:36:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-K1V13LI, 62241, None)
20/03/22 21:36:26 INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-K1V13LI:62241 with 1992.9 MB RAM, BlockManagerId(driver, DESKTOP-K1V13LI, 62241, None)
20/03/22 21:36:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-K1V13LI, 62241, None)
20/03/22 21:36:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-K1V13LI, 62241, None)
20/03/22 21:36:26 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3dedb4a6{/metrics/json,null,AVAILABLE,@Spark}
20/03/22 21:36:26 INFO root: spark session created
20/03/22 21:36:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 1992.7 MB)
20/03/22 21:36:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1992.7 MB)
20/03/22 21:36:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-K1V13LI:62241 (size: 20.4 KB, free: 1992.9 MB)
20/03/22 21:36:27 INFO SparkContext: Created broadcast 0 from textFile at Demo.scala:18
20/03/22 21:36:27 INFO root: file is loaded into rdd
20/03/22 21:36:27 INFO FileInputFormat: Total input paths to process : 1
20/03/22 21:36:27 INFO SparkContext: Starting job: foreach at Demo.scala:28
20/03/22 21:36:27 INFO DAGScheduler: Registering RDD 3 (map at Demo.scala:24)
20/03/22 21:36:27 INFO DAGScheduler: Registering RDD 5 (map at Demo.scala:26)
20/03/22 21:36:27 INFO DAGScheduler: Got job 0 (foreach at Demo.scala:28) with 1 output partitions
20/03/22 21:36:27 INFO DAGScheduler: Final stage: ResultStage 2 (foreach at Demo.scala:28)
20/03/22 21:36:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/03/22 21:36:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/03/22 21:36:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Demo.scala:24), which has no missing parents
20/03/22 21:36:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1992.7 MB)
20/03/22 21:36:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1992.7 MB)
20/03/22 21:36:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-K1V13LI:62241 (size: 2.9 KB, free: 1992.9 MB)
20/03/22 21:36:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
20/03/22 21:36:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Demo.scala:24) (first 15 tasks are for partitions Vector(0))
20/03/22 21:36:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/03/22 21:36:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7887 bytes)
20/03/22 21:36:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/03/22 21:36:28 INFO HadoopRDD: Input split: file:/C:/Users/Rajesh/Desktop/test.txt:0+6845
20/03/22 21:36:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1156 bytes result sent to driver
20/03/22 21:36:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 461 ms on localhost (executor driver) (1/1)
20/03/22 21:36:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/22 21:36:28 INFO DAGScheduler: ShuffleMapStage 0 (map at Demo.scala:24) finished in 0.643 s
20/03/22 21:36:28 INFO DAGScheduler: looking for newly runnable stages
20/03/22 21:36:28 INFO DAGScheduler: running: Set()
20/03/22 21:36:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
20/03/22 21:36:28 INFO DAGScheduler: failed: Set()
20/03/22 21:36:28 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Demo.scala:26), which has no missing parents
20/03/22 21:36:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 1992.7 MB)
20/03/22 21:36:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1992.7 MB)
20/03/22 21:36:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-K1V13LI:62241 (size: 2.4 KB, free: 1992.9 MB)
20/03/22 21:36:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
20/03/22 21:36:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Demo.scala:26) (first 15 tasks are for partitions Vector(0))
20/03/22 21:36:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/03/22 21:36:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7651 bytes)
20/03/22 21:36:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/03/22 21:36:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:36:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
20/03/22 21:36:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-K1V13LI:62241 in memory (size: 2.9 KB, free: 1992.9 MB)
20/03/22 21:36:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1328 bytes result sent to driver
20/03/22 21:36:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 160 ms on localhost (executor driver) (1/1)
20/03/22 21:36:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/03/22 21:36:28 INFO DAGScheduler: ShuffleMapStage 1 (map at Demo.scala:26) finished in 0.192 s
20/03/22 21:36:28 INFO DAGScheduler: looking for newly runnable stages
20/03/22 21:36:28 INFO DAGScheduler: running: Set()
20/03/22 21:36:28 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/03/22 21:36:28 INFO DAGScheduler: failed: Set()
20/03/22 21:36:28 INFO DAGScheduler: Submitting ResultStage 2 (ShuffledRDD[6] at sortByKey at Demo.scala:26), which has no missing parents
20/03/22 21:36:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 1992.7 MB)
20/03/22 21:36:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1992.7 MB)
20/03/22 21:36:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-K1V13LI:62241 (size: 2.1 KB, free: 1992.9 MB)
20/03/22 21:36:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
20/03/22 21:36:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[6] at sortByKey at Demo.scala:26) (first 15 tasks are for partitions Vector(0))
20/03/22 21:36:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/03/22 21:36:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
20/03/22 21:36:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/03/22 21:36:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:36:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/22 21:36:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1138 bytes result sent to driver
20/03/22 21:36:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 60 ms on localhost (executor driver) (1/1)
20/03/22 21:36:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/03/22 21:36:28 INFO DAGScheduler: ResultStage 2 (foreach at Demo.scala:28) finished in 0.076 s
20/03/22 21:36:28 INFO DAGScheduler: Job 0 finished: foreach at Demo.scala:28, took 1.304613 s
20/03/22 21:36:28 INFO root: shutting down spark
20/03/22 21:36:28 INFO AbstractConnector: Stopped Spark@2e720162{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/03/22 21:36:28 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-K1V13LI:4040
20/03/22 21:36:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/22 21:36:28 INFO MemoryStore: MemoryStore cleared
20/03/22 21:36:28 INFO BlockManager: BlockManager stopped
20/03/22 21:36:28 INFO BlockManagerMaster: BlockManagerMaster stopped
20/03/22 21:36:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/22 21:36:28 INFO SparkContext: Successfully stopped SparkContext
20/03/22 21:36:28 INFO ShutdownHookManager: Shutdown hook called
20/03/22 21:36:28 INFO ShutdownHookManager: Deleting directory C:\Users\Rajesh\AppData\Local\Temp\spark-92d2ffa4-06ea-4e09-b008-eb9a57e890c7
20/03/22 21:40:08 INFO SparkContext: Running Spark version 2.4.1
20/03/22 21:40:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/22 21:40:08 INFO SparkContext: Submitted application: wordcount
20/03/22 21:40:08 INFO SecurityManager: Changing view acls to: Rajesh
20/03/22 21:40:08 INFO SecurityManager: Changing modify acls to: Rajesh
20/03/22 21:40:08 INFO SecurityManager: Changing view acls groups to: 
20/03/22 21:40:08 INFO SecurityManager: Changing modify acls groups to: 
20/03/22 21:40:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Rajesh); groups with view permissions: Set(); users  with modify permissions: Set(Rajesh); groups with modify permissions: Set()
20/03/22 21:40:09 INFO Utils: Successfully started service 'sparkDriver' on port 62259.
20/03/22 21:40:09 INFO SparkEnv: Registering MapOutputTracker
20/03/22 21:40:09 INFO SparkEnv: Registering BlockManagerMaster
20/03/22 21:40:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/03/22 21:40:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/03/22 21:40:10 INFO DiskBlockManager: Created local directory at C:\Users\Rajesh\AppData\Local\Temp\blockmgr-5d6e368f-8ef0-4a60-97c7-25484d446f9b
20/03/22 21:40:10 INFO MemoryStore: MemoryStore started with capacity 1992.9 MB
20/03/22 21:40:10 INFO SparkEnv: Registering OutputCommitCoordinator
20/03/22 21:40:10 INFO log: Logging initialized @8044ms
20/03/22 21:40:10 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/03/22 21:40:10 INFO Server: Started @8137ms
20/03/22 21:40:10 INFO AbstractConnector: Started ServerConnector@1643d68f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/03/22 21:40:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@d5ae57e{/jobs,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4c168660{/jobs/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@52b56a3e{/jobs/job,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@36b0fcd5{/stages,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@716a7124{/stages/stage/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@77192705{/stages/pool,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@226642a5{/stages/pool/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7e809b79{/storage,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5cc126dc{/storage/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@625e134e{/storage/rdd,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@72bd06ca{/storage/rdd/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@89c10b7{/environment,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5dbe30be{/environment/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fe89c24{/executors,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@55795845{/executors/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3d08f3f5{/executors/threadDump,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@119f1f2a{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1a1da881{/static,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@53e211ee{/,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@41a90fa8{/api,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@18a3962d{/jobs/job/kill,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@78aea4b9{/stages/stage/kill,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-K1V13LI:4040
20/03/22 21:40:10 INFO Executor: Starting executor ID driver on host localhost
20/03/22 21:40:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62268.
20/03/22 21:40:10 INFO NettyBlockTransferService: Server created on DESKTOP-K1V13LI:62268
20/03/22 21:40:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/03/22 21:40:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-K1V13LI, 62268, None)
20/03/22 21:40:10 INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-K1V13LI:62268 with 1992.9 MB RAM, BlockManagerId(driver, DESKTOP-K1V13LI, 62268, None)
20/03/22 21:40:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-K1V13LI, 62268, None)
20/03/22 21:40:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-K1V13LI, 62268, None)
20/03/22 21:40:10 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3dedb4a6{/metrics/json,null,AVAILABLE,@Spark}
20/03/22 21:40:10 INFO Demo$: spark session created
20/03/22 21:40:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 1992.7 MB)
20/03/22 21:40:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1992.7 MB)
20/03/22 21:40:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-K1V13LI:62268 (size: 20.4 KB, free: 1992.9 MB)
20/03/22 21:40:11 INFO SparkContext: Created broadcast 0 from textFile at Demo.scala:19
20/03/22 21:40:11 INFO Demo$: file is loaded into rdd
20/03/22 21:40:11 INFO FileInputFormat: Total input paths to process : 1
20/03/22 21:40:11 INFO SparkContext: Starting job: foreach at Demo.scala:29
20/03/22 21:40:12 INFO DAGScheduler: Registering RDD 3 (map at Demo.scala:25)
20/03/22 21:40:12 INFO DAGScheduler: Registering RDD 5 (map at Demo.scala:27)
20/03/22 21:40:12 INFO DAGScheduler: Got job 0 (foreach at Demo.scala:29) with 1 output partitions
20/03/22 21:40:12 INFO DAGScheduler: Final stage: ResultStage 2 (foreach at Demo.scala:29)
20/03/22 21:40:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/03/22 21:40:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/03/22 21:40:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Demo.scala:25), which has no missing parents
20/03/22 21:40:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1992.7 MB)
20/03/22 21:40:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1992.7 MB)
20/03/22 21:40:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-K1V13LI:62268 (size: 2.9 KB, free: 1992.9 MB)
20/03/22 21:40:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
20/03/22 21:40:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Demo.scala:25) (first 15 tasks are for partitions Vector(0))
20/03/22 21:40:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/03/22 21:40:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7887 bytes)
20/03/22 21:40:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/03/22 21:40:12 INFO HadoopRDD: Input split: file:/C:/Users/Rajesh/Desktop/test.txt:0+6845
20/03/22 21:40:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1113 bytes result sent to driver
20/03/22 21:40:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 378 ms on localhost (executor driver) (1/1)
20/03/22 21:40:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/22 21:40:12 INFO DAGScheduler: ShuffleMapStage 0 (map at Demo.scala:25) finished in 0.526 s
20/03/22 21:40:12 INFO DAGScheduler: looking for newly runnable stages
20/03/22 21:40:12 INFO DAGScheduler: running: Set()
20/03/22 21:40:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
20/03/22 21:40:12 INFO DAGScheduler: failed: Set()
20/03/22 21:40:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Demo.scala:27), which has no missing parents
20/03/22 21:40:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 1992.7 MB)
20/03/22 21:40:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1992.7 MB)
20/03/22 21:40:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-K1V13LI:62268 (size: 2.4 KB, free: 1992.9 MB)
20/03/22 21:40:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
20/03/22 21:40:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Demo.scala:27) (first 15 tasks are for partitions Vector(0))
20/03/22 21:40:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/03/22 21:40:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7651 bytes)
20/03/22 21:40:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/03/22 21:40:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:40:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
20/03/22 21:40:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-K1V13LI:62268 in memory (size: 2.9 KB, free: 1992.9 MB)
20/03/22 21:40:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1371 bytes result sent to driver
20/03/22 21:40:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 130 ms on localhost (executor driver) (1/1)
20/03/22 21:40:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/03/22 21:40:12 INFO DAGScheduler: ShuffleMapStage 1 (map at Demo.scala:27) finished in 0.158 s
20/03/22 21:40:12 INFO DAGScheduler: looking for newly runnable stages
20/03/22 21:40:12 INFO DAGScheduler: running: Set()
20/03/22 21:40:12 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/03/22 21:40:12 INFO DAGScheduler: failed: Set()
20/03/22 21:40:12 INFO DAGScheduler: Submitting ResultStage 2 (ShuffledRDD[6] at sortByKey at Demo.scala:27), which has no missing parents
20/03/22 21:40:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 1992.7 MB)
20/03/22 21:40:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1992.7 MB)
20/03/22 21:40:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-K1V13LI:62268 (size: 2.1 KB, free: 1992.9 MB)
20/03/22 21:40:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
20/03/22 21:40:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[6] at sortByKey at Demo.scala:27) (first 15 tasks are for partitions Vector(0))
20/03/22 21:40:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/03/22 21:40:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
20/03/22 21:40:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/03/22 21:40:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:40:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/22 21:40:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1138 bytes result sent to driver
20/03/22 21:40:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 63 ms on localhost (executor driver) (1/1)
20/03/22 21:40:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/03/22 21:40:12 INFO DAGScheduler: ResultStage 2 (foreach at Demo.scala:29) finished in 0.079 s
20/03/22 21:40:12 INFO DAGScheduler: Job 0 finished: foreach at Demo.scala:29, took 1.130036 s
20/03/22 21:40:12 INFO Demo$: shutting down spark
20/03/22 21:40:12 INFO AbstractConnector: Stopped Spark@1643d68f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/03/22 21:40:12 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-K1V13LI:4040
20/03/22 21:40:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/22 21:40:12 INFO MemoryStore: MemoryStore cleared
20/03/22 21:40:12 INFO BlockManager: BlockManager stopped
20/03/22 21:40:12 INFO BlockManagerMaster: BlockManagerMaster stopped
20/03/22 21:40:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/22 21:40:12 INFO SparkContext: Successfully stopped SparkContext
20/03/22 21:40:12 INFO ShutdownHookManager: Shutdown hook called
20/03/22 21:40:12 INFO ShutdownHookManager: Deleting directory C:\Users\Rajesh\AppData\Local\Temp\spark-ff1ba921-5bee-4fdc-b24a-836ca54a2ae5
20/03/22 21:52:31 INFO SparkContext: Running Spark version 2.4.1
20/03/22 21:52:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/03/22 21:52:32 INFO SparkContext: Submitted application: wordcount
20/03/22 21:52:32 INFO SecurityManager: Changing view acls to: Rajesh
20/03/22 21:52:32 INFO SecurityManager: Changing modify acls to: Rajesh
20/03/22 21:52:32 INFO SecurityManager: Changing view acls groups to: 
20/03/22 21:52:32 INFO SecurityManager: Changing modify acls groups to: 
20/03/22 21:52:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Rajesh); groups with view permissions: Set(); users  with modify permissions: Set(Rajesh); groups with modify permissions: Set()
20/03/22 21:52:33 INFO Utils: Successfully started service 'sparkDriver' on port 62307.
20/03/22 21:52:33 INFO SparkEnv: Registering MapOutputTracker
20/03/22 21:52:33 INFO SparkEnv: Registering BlockManagerMaster
20/03/22 21:52:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/03/22 21:52:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/03/22 21:52:33 INFO DiskBlockManager: Created local directory at C:\Users\Rajesh\AppData\Local\Temp\blockmgr-44fadced-3f2f-460b-a21e-db4b0d099163
20/03/22 21:52:33 INFO MemoryStore: MemoryStore started with capacity 1992.9 MB
20/03/22 21:52:34 INFO SparkEnv: Registering OutputCommitCoordinator
20/03/22 21:52:34 INFO log: Logging initialized @7903ms
20/03/22 21:52:34 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
20/03/22 21:52:34 INFO Server: Started @7988ms
20/03/22 21:52:34 INFO AbstractConnector: Started ServerConnector@b3e79dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/03/22 21:52:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@319988b0{/jobs,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3c0fae6c{/jobs/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4c168660{/jobs/job,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@fd0e5b6{/jobs/job/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4eed46ee{/stages,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@36b0fcd5{/stages/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5241cf67{/stages/stage/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@716a7124{/stages/pool,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@77192705{/stages/pool/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@226642a5{/storage,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7e809b79{/storage/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5cc126dc{/storage/rdd,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@625e134e{/storage/rdd/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@72bd06ca{/environment,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@89c10b7{/environment/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5dbe30be{/executors,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4fe89c24{/executors/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@55795845{/executors/threadDump,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3d08f3f5{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@119f1f2a{/static,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5d465e4b{/,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@53e211ee{/api,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@117e0fe5{/jobs/job/kill,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@18a3962d{/stages/stage/kill,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-K1V13LI:4040
20/03/22 21:52:34 INFO Executor: Starting executor ID driver on host localhost
20/03/22 21:52:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62316.
20/03/22 21:52:34 INFO NettyBlockTransferService: Server created on DESKTOP-K1V13LI:62316
20/03/22 21:52:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/03/22 21:52:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-K1V13LI, 62316, None)
20/03/22 21:52:34 INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-K1V13LI:62316 with 1992.9 MB RAM, BlockManagerId(driver, DESKTOP-K1V13LI, 62316, None)
20/03/22 21:52:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-K1V13LI, 62316, None)
20/03/22 21:52:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-K1V13LI, 62316, None)
20/03/22 21:52:34 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4a325eb9{/metrics/json,null,AVAILABLE,@Spark}
20/03/22 21:52:34 INFO Demo$: spark session created
20/03/22 21:52:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 1992.7 MB)
20/03/22 21:52:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1992.7 MB)
20/03/22 21:52:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on DESKTOP-K1V13LI:62316 (size: 20.4 KB, free: 1992.9 MB)
20/03/22 21:52:35 INFO SparkContext: Created broadcast 0 from textFile at Demo.scala:20
20/03/22 21:52:35 INFO Demo$: file is loaded into rdd
20/03/22 21:52:35 INFO FileInputFormat: Total input paths to process : 1
20/03/22 21:52:35 INFO SparkContext: Starting job: foreach at Demo.scala:30
20/03/22 21:52:35 INFO DAGScheduler: Registering RDD 3 (map at Demo.scala:26)
20/03/22 21:52:35 INFO DAGScheduler: Registering RDD 5 (map at Demo.scala:28)
20/03/22 21:52:36 INFO DAGScheduler: Got job 0 (foreach at Demo.scala:30) with 1 output partitions
20/03/22 21:52:36 INFO DAGScheduler: Final stage: ResultStage 2 (foreach at Demo.scala:30)
20/03/22 21:52:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/03/22 21:52:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/03/22 21:52:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Demo.scala:26), which has no missing parents
20/03/22 21:52:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 1992.7 MB)
20/03/22 21:52:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1992.7 MB)
20/03/22 21:52:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on DESKTOP-K1V13LI:62316 (size: 2.9 KB, free: 1992.9 MB)
20/03/22 21:52:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
20/03/22 21:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at Demo.scala:26) (first 15 tasks are for partitions Vector(0))
20/03/22 21:52:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/03/22 21:52:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7887 bytes)
20/03/22 21:52:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/03/22 21:52:36 INFO HadoopRDD: Input split: file:/C:/Users/Rajesh/Desktop/test.txt:0+6845
20/03/22 21:52:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1156 bytes result sent to driver
20/03/22 21:52:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 412 ms on localhost (executor driver) (1/1)
20/03/22 21:52:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/03/22 21:52:36 INFO DAGScheduler: ShuffleMapStage 0 (map at Demo.scala:26) finished in 0.581 s
20/03/22 21:52:36 INFO DAGScheduler: looking for newly runnable stages
20/03/22 21:52:36 INFO DAGScheduler: running: Set()
20/03/22 21:52:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
20/03/22 21:52:36 INFO DAGScheduler: failed: Set()
20/03/22 21:52:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Demo.scala:28), which has no missing parents
20/03/22 21:52:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 1992.7 MB)
20/03/22 21:52:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1992.7 MB)
20/03/22 21:52:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on DESKTOP-K1V13LI:62316 (size: 2.5 KB, free: 1992.9 MB)
20/03/22 21:52:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
20/03/22 21:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at map at Demo.scala:28) (first 15 tasks are for partitions Vector(0))
20/03/22 21:52:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/03/22 21:52:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7651 bytes)
20/03/22 21:52:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/03/22 21:52:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
20/03/22 21:52:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on DESKTOP-K1V13LI:62316 in memory (size: 2.9 KB, free: 1992.9 MB)
20/03/22 21:52:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1371 bytes result sent to driver
20/03/22 21:52:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 171 ms on localhost (executor driver) (1/1)
20/03/22 21:52:36 INFO DAGScheduler: ShuffleMapStage 1 (map at Demo.scala:28) finished in 0.203 s
20/03/22 21:52:36 INFO DAGScheduler: looking for newly runnable stages
20/03/22 21:52:36 INFO DAGScheduler: running: Set()
20/03/22 21:52:36 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/03/22 21:52:36 INFO DAGScheduler: failed: Set()
20/03/22 21:52:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/03/22 21:52:36 INFO DAGScheduler: Submitting ResultStage 2 (ShuffledRDD[6] at sortByKey at Demo.scala:28), which has no missing parents
20/03/22 21:52:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.4 KB, free 1992.7 MB)
20/03/22 21:52:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1992.7 MB)
20/03/22 21:52:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on DESKTOP-K1V13LI:62316 (size: 2.1 KB, free: 1992.9 MB)
20/03/22 21:52:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
20/03/22 21:52:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (ShuffledRDD[6] at sortByKey at Demo.scala:28) (first 15 tasks are for partitions Vector(0))
20/03/22 21:52:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/03/22 21:52:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
20/03/22 21:52:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/03/22 21:52:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:52:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/22 21:52:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1138 bytes result sent to driver
20/03/22 21:52:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 93 ms on localhost (executor driver) (1/1)
20/03/22 21:52:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/03/22 21:52:36 INFO DAGScheduler: ResultStage 2 (foreach at Demo.scala:30) finished in 0.108 s
20/03/22 21:52:36 INFO DAGScheduler: Job 0 finished: foreach at Demo.scala:30, took 1.317488 s
20/03/22 21:52:36 INFO LoggingDemo$: entered into another object
20/03/22 21:52:36 INFO SparkContext: Starting job: count at LoggingDemo.scala:15
20/03/22 21:52:36 INFO DAGScheduler: Got job 1 (count at LoggingDemo.scala:15) with 1 output partitions
20/03/22 21:52:36 INFO DAGScheduler: Final stage: ResultStage 5 (count at LoggingDemo.scala:15)
20/03/22 21:52:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
20/03/22 21:52:36 INFO DAGScheduler: Missing parents: List()
20/03/22 21:52:36 INFO DAGScheduler: Submitting ResultStage 5 (ShuffledRDD[6] at sortByKey at Demo.scala:28), which has no missing parents
20/03/22 21:52:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.4 KB, free 1992.7 MB)
20/03/22 21:52:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.1 KB, free 1992.7 MB)
20/03/22 21:52:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on DESKTOP-K1V13LI:62316 (size: 2.1 KB, free: 1992.9 MB)
20/03/22 21:52:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
20/03/22 21:52:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (ShuffledRDD[6] at sortByKey at Demo.scala:28) (first 15 tasks are for partitions Vector(0))
20/03/22 21:52:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/03/22 21:52:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 3, localhost, executor driver, partition 0, ANY, 7662 bytes)
20/03/22 21:52:37 INFO Executor: Running task 0.0 in stage 5.0 (TID 3)
20/03/22 21:52:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
20/03/22 21:52:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/03/22 21:52:37 INFO Executor: Finished task 0.0 in stage 5.0 (TID 3). 1090 bytes result sent to driver
20/03/22 21:52:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 3) in 47 ms on localhost (executor driver) (1/1)
20/03/22 21:52:37 INFO DAGScheduler: ResultStage 5 (count at LoggingDemo.scala:15) finished in 0.060 s
20/03/22 21:52:37 INFO DAGScheduler: Job 1 finished: count at LoggingDemo.scala:15, took 0.065431 s
20/03/22 21:52:37 INFO Demo$: shutting down spark
20/03/22 21:52:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/03/22 21:52:37 INFO AbstractConnector: Stopped Spark@b3e79dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/03/22 21:52:37 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-K1V13LI:4040
20/03/22 21:52:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/03/22 21:52:37 INFO MemoryStore: MemoryStore cleared
20/03/22 21:52:37 INFO BlockManager: BlockManager stopped
20/03/22 21:52:37 INFO BlockManagerMaster: BlockManagerMaster stopped
20/03/22 21:52:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/03/22 21:52:37 INFO SparkContext: Successfully stopped SparkContext
20/03/22 21:52:37 INFO ShutdownHookManager: Shutdown hook called
20/03/22 21:52:37 INFO ShutdownHookManager: Deleting directory C:\Users\Rajesh\AppData\Local\Temp\spark-eb78f053-7251-4012-86f2-562fe3cbb2c2
